{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Any, Dict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.file_management.write import WriteFileTool\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "# Define the language model and logging directories\n",
    "MODEL = 'gpt-4o'\n",
    "LOG_DIR = \"logs\"\n",
    "EXPERIMENT_LOG_FILE = os.path.join(LOG_DIR, \"experiment_logs.txt\")\n",
    "AGENT_LOG_FILE = os.path.join(LOG_DIR, \"agent_log.txt\")\n",
    "\n",
    "# Ensure the log directory exists\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "# Set an environment variable for the project name in Langsmith\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Re-Act HPO\"\n",
    "\n",
    "# Configure logging to output to the notebook output area\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.info(\"Notebook started\")\n",
    "\n",
    "\n",
    "# Information about the dataset being used\n",
    "dataset_information = \"\"\"\n",
    "                    Name: Census Income Dataset\n",
    "                    Task Description: Predict if an individual earns more than $50,000 per year based on census data.\n",
    "                    Label: Income (binary classification: \">50K\" or \"<=50K\")\n",
    "                    Key Features:\n",
    "                    age: Integer (e.g., 25, 42)\n",
    "                    workclass: Categorical (e.g., Private, State-gov)\n",
    "                    education-num: Integer (corresponding to educational level)\n",
    "                    marital-status: Categorical (e.g., Never-married, Married-civ-spouse)\n",
    "                    occupation: Categorical (e.g., Exec-managerial, Handlers-cleaners)\n",
    "                    relationship: Categorical (e.g., Husband, Not-in-family)\n",
    "                    race: Categorical (e.g., White, Asian-Pac-Islander)\n",
    "                    sex: Categorical (Male, Female)\n",
    "                    capital-gain: Continuous\n",
    "                    capital-loss: Continuous\n",
    "                    hours-per-week: Continuous\n",
    "                    native-country: Categorical (e.g., United-States, India)\n",
    "                    Evaluation Metric: Area Under the ROC Curve (AUC)\n",
    "                    \"\"\"\n",
    "\n",
    "# Model information\n",
    "model_information = \"\"\"\n",
    "                    Model Type: Random Forest Classifier\n",
    "                    Library Used: Scikit-learn (assuming you are using Python)\n",
    "                    Purpose: To classify individuals based on their income level (>50K or <=50K).\n",
    "                    Key Parameters to Optimize:\n",
    "                    n_estimators: Number of trees in the forest (e.g., 100, 200).\n",
    "                    max_depth: The maximum depth of the tree (e.g., 10, 20, None).\n",
    "                    min_samples_split: The minimum number of samples required to split an internal node (e.g., 2, 5).\n",
    "                    min_samples_leaf: The minimum number of samples required to be at a leaf node (e.g., 1, 2).                  \n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "# Optimization goal for the hyperparameters\n",
    "\n",
    "optimization_goal = \"\"\"Maximize the AUC Score on test data by optimizing the following hyperparameters of the model:\n",
    "{\n",
    "    'n_estimators': int   # Range for number of trees in the forest\n",
    "    'max_depth': int      # Maximum depth of each tree\n",
    "    'min_samples_split': int # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': int # Minimum number of samples required at a leaf node\n",
    "}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "# Define a Pydantic model for our input schema\n",
    "class Hyperparameters(BaseModel):\n",
    "    n_estimators: int = Field(description=\"The number of trees in the forest.\")\n",
    "    max_depth: int = Field(description=\"The maximum depth of the trees.\")\n",
    "    min_samples_split: int = Field(description=\"The minimum number of samples required to split an internal node.\")\n",
    "    min_samples_leaf: int = Field(description=\"The minimum number of samples required to be at a leaf node.\")\n",
    "\n",
    "# Function to load and preprocess the Census Income dataset\n",
    "def preprocess_data() -> (pd.DataFrame, pd.Series):\n",
    "    \"\"\"\n",
    "    Load and preprocess the Census Income dataset.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing preprocessed features (X) and target (y).\n",
    "    \"\"\"\n",
    "    # Load the Census Income dataset\n",
    "    census = fetch_openml(name='adult', version=2, as_frame=True)\n",
    "    X = census.data\n",
    "    y = (census.target == '>50K').astype(int)  # Convert target to binary classification\n",
    "\n",
    "    # Preprocess data (convert categorical to numeric)\n",
    "    X = pd.get_dummies(X)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Function to log the output of the agent after each cycle of task, thought, action, and observation\n",
    "def log_agent_output(output, file_path=AGENT_LOG_FILE):\n",
    "    \"\"\"\n",
    "    Logs the 'content' of the output to the specified file path and returns the output unchanged.\n",
    "    \n",
    "    Args:\n",
    "        output (dict): The output from the agent to be logged and returned.\n",
    "        file_path (str): The path to the file where the output 'content' will be logged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract content from the output\n",
    "        content = getattr(output, 'content', 'No content available')\n",
    "\n",
    "        # Open the file in append the content\n",
    "        with open(file_path, 'a') as f:\n",
    "            f.write(content + \"\\n\\n\")\n",
    "\n",
    "        # Also log to the main log file\n",
    "        logging.info(f\"Agent's chain of thought logged to {file_path}\")\n",
    "\n",
    "        # Return the output unchanged for further processing\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in log_agent_output: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools for the agent\n",
    "\n",
    "# Custom Tool to train a Random Forest model with given hyperparameters\n",
    "@tool(\"train_random_forest\",args_schema=Hyperparameters)\n",
    "def train_random_forest(**hyperparameters) -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Train a Random Forest model with given hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "        hyperparameters: dict\n",
    "    \n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Received hyperparameters by train_random_forest tool: {hyperparameters}\")\n",
    "        # Ensure all hyperparameters are provided\n",
    "        required_keys = ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf']\n",
    "        for key in required_keys:\n",
    "            if key not in hyperparameters:\n",
    "                raise ValueError(f\"Missing required hyperparameter: {key}\")\n",
    "        \n",
    "        # Preprocess the data and split into training/test set\n",
    "        X,y = preprocess_data()\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "        \n",
    "        # Initialize the Random Forest model with the provided hyperparameters\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=hyperparameters.get('n_estimators'),\n",
    "            max_depth=hyperparameters.get('max_depth'),\n",
    "            min_samples_split=hyperparameters.get('min_samples_split'),\n",
    "            min_samples_leaf=hyperparameters.get('min_samples_leaf'),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Train the model and measure the time taken\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Predict probabilities and calculate AUC\n",
    "        y_pred = model.predict_proba(X_valid)[:, 1]\n",
    "        auc = roc_auc_score(y_valid, y_pred)\n",
    "        \n",
    "        # Return the results as a dictionary\n",
    "        return {'auc': auc, 'training_time': training_time}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in train_random_forest: {e}\")\n",
    "        raise\n",
    "\n",
    "# Define tools to be used by the agent, WriteFileTool from langchain_community and train_random_forest\n",
    "tools = [WriteFileTool(file_path=EXPERIMENT_LOG_FILE), train_random_forest]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create an agent for optimizing model hyperparameters\n",
    "def create_agent(llm, tools, file_path, model_information, dataset_information, optimization_goal):\n",
    "    \"\"\"\n",
    "    Create an agent for optimizing model hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        llm: The language model instance.\n",
    "        tools: The tools to be used by the agent.\n",
    "        file_path (str): Path to the log file.\n",
    "        model_information (str): Information about the model.\n",
    "        dataset_information (str): Information about the dataset.\n",
    "        optimization_goal (str): The optimization goal for hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        agent: The created agent instance.\n",
    "    \"\"\"\n",
    "    # Define the prompt template for the agent\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are the machine learning experimenter tasked with optimizing the model’s hyperparameter settings to accomplish the following objective: {optim_goal}.\n",
    "                To achieve this, propose an initial set of default hyperparameters and test them on the model using the following tool:\n",
    "                Name: `train-random-forest`\n",
    "                Description: ”Useful for when you need to train a random forest model with given hyperparameters”\n",
    "                \n",
    "                Analyze the outcome of that training and iteratively improve the proposed hyperparameters to methodically reach the final objective.\n",
    "                Ensure your proposed hyperparameters are distinct from those previously tested.\n",
    "                Keep iterating until the desired metric has no longer improved for the previous 5 iterations.\n",
    "                Below is the basic information about the experimental settings:\n",
    "                Model Info: {model_info}\n",
    "                Dataset Info: {dataset_info}\n",
    "\n",
    "                Use the following format:\n",
    "                Task: the input task you must solve\n",
    "                Thought: you should always think about what to do\n",
    "                Action: the action to take\n",
    "                Action Input: the input to the action\n",
    "                Observation: the result of the action\n",
    "                ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "                Thought: I now know the final answer\n",
    "                Final Answer: the final answer to the original input question\n",
    "\n",
    "                Finally, analyze all the iterations and make a detailed summary of the entire experiment for a ML beginner.\n",
    "                Make sure you touch on all of the the following points in your detailed summary:\n",
    "                - best hyperparameters\n",
    "                - details of the training trajectory and final training results about this experiment.\n",
    "                - the thought process behind those adjustments in hyperparameter values and how those parameters impacted the model given the dataset.\n",
    "                - detailed first principle analysis on what worked and why.\n",
    "\n",
    "                Once complete, log this summary into {file_path} using the following tool:\n",
    "                Name: `write_file`\n",
    "                Description: ”Useful for when you need to write the experiment summary to a file”\n",
    "                Begin!\n",
    "                Task: {input}\n",
    "                Thought: {agent_scratchpad}\n",
    "                \"\"\"\n",
    "            ),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    # Partially fill in the prompt with the provided information\n",
    "    prompt = prompt.partial(file_path=file_path)\n",
    "    prompt = prompt.partial(model_info=model_information)\n",
    "    prompt = prompt.partial(dataset_info=dataset_information)\n",
    "    prompt = prompt.partial(optim_goal=optimization_goal)\n",
    "\n",
    "    # Bind tools to the language model\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    # Create the agent with the specified components\n",
    "    agent = (\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "                x[\"intermediate_steps\"]\n",
    "            ),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm_with_tools\n",
    "        | log_agent_output\n",
    "        | OpenAIToolsAgentOutputParser()\n",
    "    )\n",
    "\n",
    "    return agent\n",
    "\n",
    "# Initialize the language model and create the agent\n",
    "llm = ChatOpenAI(model=MODEL, streaming=True)\n",
    "agent = create_agent(llm,tools, EXPERIMENT_LOG_FILE, model_information, dataset_information, optimization_goal)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the input task for the agent\n",
    "input_task = \"Tune the hyperparameters of the given model to achieve the highest AUC score.\"\n",
    "\n",
    "# Invoke the agent with the input task\n",
    "result = agent_executor.invoke({\"input\": input_task})\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Stream the output and capture chunks\n",
    "chunks = []\n",
    "try:\n",
    "    for chunk in agent_executor.stream({\"input\": input_task}):\n",
    "        chunks.append(chunk)\n",
    "        print(\"------\")\n",
    "        pprint.pprint(chunk)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error executing agent: {e}\")\n",
    "    print(f\"Error executing agent: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "The following sections in the notebook are written purely to elucidate what some of the code abstractions in langchain do.\n",
    "This is useful for an explicit understanding ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does OpenAIToolsAgentOutputParser() do?\n",
    "\n",
    "\n",
    "https://api.python.langchain.com/en/latest/agents/langchain.agents.output_parsers.openai_tools.OpenAIToolsAgentOutputParser.html\n",
    "\n",
    "\n",
    "After the LLM generates a response, this parser takes the LLM's output and converts it into actionable steps (AgentAction objects)\n",
    "or determines if the process has reached its conclusion (AgentFinish object).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolAgentAction(tool='train_random_forest', tool_input={'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}, log=\"\\nInvoking: `train_random_forest` with `{'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_7RcVoJImJQ2uQbMf3gZL8KxN', 'function': {'arguments': '{\"n_estimators\": 200, \"max_depth\": 20, \"min_samples_split\": 5, \"min_samples_leaf\": 2}', 'name': 'train_random_forest'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-4b2391cf-90a2-4c38-801c-0988f40c9a80-0', tool_calls=[{'name': 'train_random_forest', 'args': {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}, 'id': 'call_7RcVoJImJQ2uQbMf3gZL8KxN'}])], tool_call_id='call_7RcVoJImJQ2uQbMf3gZL8KxN')]\n"
     ]
    }
   ],
   "source": [
    "#Example of invoking the output parser\n",
    "output = AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_7RcVoJImJQ2uQbMf3gZL8KxN', 'function': {'arguments': '{\"n_estimators\": 200, \"max_depth\": 20, \"min_samples_split\": 5, \"min_samples_leaf\": 2}', 'name': 'train_random_forest'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-4b2391cf-90a2-4c38-801c-0988f40c9a80-0', tool_calls=[{'name': 'train_random_forest', 'args': {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2}, 'id': 'call_7RcVoJImJQ2uQbMf3gZL8KxN'}])\n",
    "parser =  OpenAIToolsAgentOutputParser()\n",
    "print(parser.invoke(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does format_to_openai_tool_messages do?\n",
    "Takes the intermediate steps and converts them to a list of base messages that can be fed back to LLM for context\n",
    "\n",
    "https://api.python.langchain.com/en/latest/agents/langchain.agents.format_scratchpad.openai_tools.format_to_openai_tool_messages.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of format_to_openai_tool_messages\n",
    "from langchain_core.agents import AgentAction\n",
    "from langchain_core.messages import ToolMessage, AIMessage, BaseMessage\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolAgentAction\n",
    "\n",
    "\n",
    "action1 = OpenAIToolAgentAction(\n",
    "    tool=\"database_query\",\n",
    "    tool_input={\"query\": \"SELECT * FROM users\"},\n",
    "    log=\"Querying the database for user information\",\n",
    "    tool_call_id=\"1\",\n",
    "    message_log=[]\n",
    ")\n",
    "observation1 = \"[{'id': 1, 'name': 'Alice'}, {'id': 2, 'name': 'Bob'}]\"\n",
    "\n",
    "action2 = OpenAIToolAgentAction(\n",
    "    tool=\"data_processing\",\n",
    "    tool_input=observation1,\n",
    "    log=\"Processing user data\",\n",
    "    tool_call_id=\"2\",\n",
    "    message_log=[]\n",
    ")\n",
    "observation2 = '{\"user_count\": 2}'\n",
    "\n",
    "\n",
    "intermediate_steps = [(action1, observation1), (action2, observation2)]\n",
    "\n",
    "messages = format_to_openai_tool_messages(intermediate_steps)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
